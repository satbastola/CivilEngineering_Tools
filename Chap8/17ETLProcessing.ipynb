{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dee526d-80b1-45c3-add7-9abfe88b351c",
   "metadata": {},
   "source": [
    "### üß† ETL: Extract, Transform, Load ‚Äì Foundation of Data-Driven Intelligence\n",
    "\n",
    "### 1Ô∏è‚É£ What is ETL?\n",
    "\n",
    "**ETL (Extract, Transform, Load)** is a foundational process in data engineering and business intelligence. It refers to:\n",
    "\n",
    "- **Extract**: Pulling raw data from various sources (databases, APIs, files, sensors)\n",
    "- **Transform**: Cleaning, reshaping, and enriching data to make it usable\n",
    "- **Load**: Storing the processed data into a target system (e.g., data warehouse, dashboard)\n",
    "\n",
    "> ETL enables organizations to convert scattered, messy data into structured insights for decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Why is ETL Important for Business Intelligence?\n",
    "\n",
    "- Ensures **data consistency** across systems  \n",
    "- Enables **real-time analytics** and reporting  \n",
    "- Supports **data governance** and compliance  \n",
    "- Powers **dashboards, KPIs, and predictive models**  \n",
    "- Facilitates **scalable integration** of diverse data sources\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ How Does ETL Work?\n",
    "\n",
    "1. **Data Extraction**  \n",
    "   - Connect to source systems  \n",
    "   - Retrieve raw data (structured, semi-structured, unstructured)\n",
    "\n",
    "2. **Data Transformation**  \n",
    "   - Clean missing or inconsistent values  \n",
    "   - Normalize formats and units  \n",
    "   - Apply business rules and calculations  \n",
    "   - Join, filter, aggregate, encode\n",
    "\n",
    "3. **Data Loading**  \n",
    "   - Insert into target systems (SQL, NoSQL, cloud storage)  \n",
    "   - Schedule batch or stream updates  \n",
    "   - Validate and monitor data integrity\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ What is Data Extraction?\n",
    "\n",
    "Data extraction is the process of retrieving raw data from its origin. It can involve:\n",
    "\n",
    "- **Structured sources**: SQL databases, spreadsheets  \n",
    "- **Semi-structured**: JSON, XML, logs  \n",
    "- **Unstructured**: PDFs, images, text files  \n",
    "- **Real-time streams**: IoT sensors, APIs\n",
    "\n",
    "---\n",
    "\n",
    "### 5Ô∏è‚É£ Methods of Data Extraction\n",
    "\n",
    "| Method              | Description                                                                 |\n",
    "|---------------------|-----------------------------------------------------------------------------|\n",
    "| Full Extraction     | Pulls all data at once (simple but inefficient for large systems)           |\n",
    "| Incremental         | Extracts only new or changed data (efficient, requires change tracking)     |\n",
    "| API-based           | Uses RESTful or GraphQL endpoints to fetch data dynamically                 |\n",
    "| Log-based           | Monitors database logs for changes (used in CDC systems)                    |\n",
    "| Query-based         | Executes SQL queries to extract specific slices of data                     |\n",
    "| Web Scraping        | Extracts data from websites using HTML parsing                              |\n",
    "| Streaming           | Captures real-time data from sensors or message queues (Kafka, MQTT)        |\n",
    "\n",
    "---\n",
    "\n",
    "### 6Ô∏è‚É£ What is Data Transformation?\n",
    "\n",
    "Data transformation prepares raw data for analysis. It includes:\n",
    "\n",
    "- **Cleaning**: Handling missing values, outliers, duplicates  \n",
    "- **Normalization**: Scaling, encoding, standardizing formats  \n",
    "- **Aggregation**: Summarizing data (e.g., totals, averages)  \n",
    "- **Joining**: Merging datasets across keys  \n",
    "- **Derivation**: Creating new features or metrics  \n",
    "- **Validation**: Ensuring logical consistency and integrity\n",
    "\n",
    "> Transformation ensures that data is accurate, consistent, and aligned with analytical goals.\n",
    "\n",
    "---\n",
    "\n",
    "### 7Ô∏è‚É£ What is Data Loading?\n",
    "\n",
    "Data loading moves transformed data into its final destination:\n",
    "\n",
    "- **Batch loading**: Periodic uploads (e.g., nightly jobs)  \n",
    "- **Streaming**: Continuous updates (e.g., real-time dashboards)  \n",
    "- **Upserts**: Insert or update logic to avoid duplication  \n",
    "- **Partitioning**: Organizing data for efficient querying  \n",
    "- **Monitoring**: Ensuring successful delivery and alerting on failures\n",
    "\n",
    "---\n",
    "\n",
    "### 8Ô∏è‚É£ Challenges in ETL\n",
    "\n",
    "- Handling **schema changes** and evolving data formats  \n",
    "- Managing **data quality** and missing values  \n",
    "- Ensuring **performance** and scalability  \n",
    "- Avoiding **data duplication** and inconsistency  \n",
    "- Maintaining **security and compliance**\n",
    "\n",
    "---\n",
    "\n",
    "### 9Ô∏è‚É£ Tools & Commands to Master ETL\n",
    "\n",
    "| Category         | Tools / Commands / Libraries                                                  |\n",
    "|------------------|--------------------------------------------------------------------------------|\n",
    "| Extraction       | `pandas.read_sql()`, `requests`, `BeautifulSoup`, `pyodbc`, `sqlalchemy`       |\n",
    "| Transformation   | `pandas`, `numpy`, `scikit-learn`, `dataprep`, `dask`, `spark`                 |\n",
    "| Loading          | `to_sql()`, `boto3` (AWS), `gsutil` (GCP), `airflow`, `dbt`, `kafka`            |\n",
    "| Orchestration    | `Apache Airflow`, `Luigi`, `Dagster`, `Prefect`                                |\n",
    "| Monitoring       | `Great Expectations`, `DataDog`, `Prometheus`, `logging`, `alerts`             |\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Summary\n",
    "\n",
    "ETL is the backbone of modern data workflows. Mastering it means understanding:\n",
    "\n",
    "- Where data comes from  \n",
    "- How to clean and shape it  \n",
    "- Where and how to store it  \n",
    "- How to automate and monitor the entire pipeline\n",
    "\n",
    "> ETL is not just a technical process‚Äîit's a strategic capability for turning data into decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799953de-07c5-45b9-a801-dfddfbfb808c",
   "metadata": {},
   "source": [
    "### üîÑ Data Normalization Summary\n",
    "\n",
    "**Method Used**: `MinMax`\n",
    "\n",
    "**Purpose**:  \n",
    "Rescale features to a fixed range (typically [0, 1]) to improve model performance and comparability across features.\n",
    "\n",
    "**Why Normalize?**  \n",
    "- Ensures features contribute equally to distance-based models (e.g., KNN, clustering).\n",
    "- Prevents dominance of high-magnitude features in gradient-based optimization.\n",
    "- Improves convergence speed and stability in neural networks.\n",
    "\n",
    "**Common Use Cases**:\n",
    "\n",
    "| Method     | Description                                  | Best For                            |\n",
    "|------------|----------------------------------------------|-------------------------------------|\n",
    "| MinMax     | Scales data to [0, 1]                        | Neural networks, distance metrics   |\n",
    "| Standard   | Centers to mean 0, scales to unit variance   | Linear models, PCA                  |\n",
    "| Robust     | Uses median and IQR, resists outliers        | Noisy data, outlier-heavy datasets  |\n",
    "\n",
    "**Visual Insight**:  \n",
    "Use boxplots or histograms to compare original vs. normalized distributions. This helps students see how scaling affects spread, center, and outlier influence.\n",
    "\n",
    "**Student Prompt**:  \n",
    "> Try switching between normalization methods. Which method best preserves feature relationships? How does each affect clustering or regression outcomes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3a78dc-b03f-416f-b424-8cf037761bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## üß† Interactive Data Normalization Explorer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0448132bbb4861af7323712dff0819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Normalization Method', options=('MinMax', 'Standard', 'Robust'), value='MinMax')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b00a31c87a4c3cbc53690f03f6e450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üì¶ Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# üéØ Synthetic data\n",
    "np.random.seed(42)\n",
    "raw_data = pd.DataFrame({\n",
    "    'Feature A': np.random.normal(50, 20, 100),\n",
    "    'Feature B': np.random.exponential(10, 100),\n",
    "    'Feature C': np.random.uniform(0, 100, 100)\n",
    "})\n",
    "\n",
    "# üîç Normalization function\n",
    "def normalize_data(method='MinMax'):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if method == 'MinMax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method == 'Standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif method == 'Robust':\n",
    "        scaler = RobustScaler()\n",
    "    \n",
    "    normalized = scaler.fit_transform(raw_data)\n",
    "    df_norm = pd.DataFrame(normalized, columns=raw_data.columns)\n",
    "    \n",
    "    # üìä Plot comparison\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "  # Replace 'labels' with 'tick_labels' in both boxplot calls\n",
    "    axs[0].boxplot(raw_data.values, tick_labels=raw_data.columns)\n",
    "\n",
    "    axs[0].set_title(\"Original Data Distribution\")\n",
    "    \n",
    "    #axs[1].boxplot(df_norm.values, labels=df_norm.columns)\n",
    "    axs[1].boxplot(df_norm.values, tick_labels=df_norm.columns)\n",
    "\n",
    "    axs[1].set_title(f\"{method} Normalized Distribution\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # üìò Summary\n",
    "    display(Markdown(f\"\"\"\n",
    "### üîÑ Data Normalization Summary\n",
    "- **Method Used**: `{method}`\n",
    "- **Purpose**: Rescale features to improve model performance and comparability\n",
    "- **Common Use Cases**:\n",
    "  - MinMax: Neural networks, distance-based models\n",
    "  - Standard: Linear models, PCA\n",
    "  - Robust: Outlier-resistant transformations\n",
    "\"\"\"))\n",
    "\n",
    "# üéõÔ∏è Widget\n",
    "method_dropdown = widgets.Dropdown(\n",
    "    options=['MinMax', 'Standard', 'Robust'],\n",
    "    value='MinMax',\n",
    "    description='Normalization Method'\n",
    ")\n",
    "\n",
    "# ‚ñ∂Ô∏è Display\n",
    "display(Markdown(\"### üß† Interactive Data Normalization Explorer\"))\n",
    "display(method_dropdown)\n",
    "widgets.interactive_output(normalize_data, {'method': method_dropdown})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bad9fc-be40-4432-8e5c-090d17017202",
   "metadata": {},
   "source": [
    "### üß™ ETL Simulation: Cleaning ‚Üí Aggregation ‚Üí Derivation\n",
    "\n",
    "This interactive module demonstrates key ETL steps using synthetic business data.\n",
    "\n",
    "### üì¶ Components\n",
    "- `numpy`, `pandas`, `scipy`: Data generation and statistical filtering\n",
    "- `ipywidgets`: Interactive controls for cleaning strategies\n",
    "- `Markdown`, `display`: Dynamic output rendering\n",
    "\n",
    "### üéØ Dataset Features\n",
    "- `Region`: Categorical variable (North, South, East, West)\n",
    "- `Sales`: Normally distributed with injected outlier\n",
    "- `Discount`: Random values with missing entries\n",
    "- `Returns`: Binary with missing entries\n",
    "- Includes intentional duplicates and outliers\n",
    "\n",
    "### üßº Cleaning Options\n",
    "- **Missing Values**: Fill with mean, median, mode, constant, or drop rows\n",
    "- **Outliers**: Remove using IQR or Z-score filtering\n",
    "- **Duplicates**: Toggle to drop repeated rows\n",
    "- **Raw Data Toggle**: View original unclean sample\n",
    "\n",
    "### üìä Aggregation\n",
    "- Grouped by `Region`\n",
    "- Summarizes total and average `Sales`, mean `Discount`, and total `Returns`\n",
    "\n",
    "### üßÆ Derivation\n",
    "- `Net Revenue = Sales √ó (1 - Discount)`\n",
    "- `Return Rate = Returns √∑ (Sales / 1000)`\n",
    "\n",
    "### üß† Learning Objectives\n",
    "- Explore how cleaning choices affect downstream metrics\n",
    "- Compare raw vs. cleaned data\n",
    "- Understand the role of derived features in business intelligence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "548723ff-0f23-4159-adcd-e14a42bda64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## üß™ ETL Simulation: Cleaning ‚Üí Aggregation ‚Üí Derivation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2652727577426fae3893b56c9624cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Show Raw Data')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ee214382e7499ea2f2e427069daff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Missing Values', options=('Fill Mean', 'Fill Median', 'Fill Mode', 'Fill Constant', 'Dro‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10e778c3b4f49e196647761f7432a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Outliers', index=1, options=('None', 'IQR', 'Z-Score'), value='IQR')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d7af969bfb4e9f8547207185f2482b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Drop Duplicates')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53af0d657554075bf169d1b41448699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='üîÅ Run ETL Simulation', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üßæ Raw Unclean Data Sample"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East</td>\n",
       "      <td>1221.539974</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West</td>\n",
       "      <td>1051.410484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North</td>\n",
       "      <td>965.305515</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>East</td>\n",
       "      <td>909.668891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>East</td>\n",
       "      <td>556.443403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region        Sales  Discount  Returns\n",
       "0   East  1221.539974       0.2      NaN\n",
       "1   West  1051.410484       NaN      NaN\n",
       "2  North   965.305515       0.1      0.0\n",
       "3   East   909.668891       NaN      0.0\n",
       "4   East   556.443403       NaN      1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ Cleaned Data Sample"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East</td>\n",
       "      <td>1221.539974</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West</td>\n",
       "      <td>1051.410484</td>\n",
       "      <td>0.190769</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North</td>\n",
       "      <td>965.305515</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>East</td>\n",
       "      <td>909.668891</td>\n",
       "      <td>0.190769</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>East</td>\n",
       "      <td>556.443403</td>\n",
       "      <td>0.190769</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region        Sales  Discount   Returns\n",
       "0   East  1221.539974  0.200000  0.537313\n",
       "1   West  1051.410484  0.190769  0.537313\n",
       "2  North   965.305515  0.100000  0.000000\n",
       "3   East   909.668891  0.190769  0.000000\n",
       "4   East   556.443403  0.190769  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìä Aggregated Summary by Region"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Sales</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>23008.46</td>\n",
       "      <td>1000.37</td>\n",
       "      <td>0.17</td>\n",
       "      <td>14.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>20681.03</td>\n",
       "      <td>1034.05</td>\n",
       "      <td>0.21</td>\n",
       "      <td>11.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>24059.35</td>\n",
       "      <td>1002.47</td>\n",
       "      <td>0.19</td>\n",
       "      <td>13.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>27511.28</td>\n",
       "      <td>948.66</td>\n",
       "      <td>0.19</td>\n",
       "      <td>13.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sales          Discount Returns\n",
       "             sum     mean     mean     sum\n",
       "Region                                    \n",
       "East    23008.46  1000.37     0.17   14.22\n",
       "North   20681.03  1034.05     0.21   11.15\n",
       "South   24059.35  1002.47     0.19   13.91\n",
       "West    27511.28   948.66     0.19   13.37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üßÆ Derived Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Net Revenue</th>\n",
       "      <th>Return Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221.539974</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>977.231979</td>\n",
       "      <td>0.439866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051.410484</td>\n",
       "      <td>0.190769</td>\n",
       "      <td>850.833715</td>\n",
       "      <td>0.511041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>965.305515</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>868.774964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>909.668891</td>\n",
       "      <td>0.190769</td>\n",
       "      <td>736.132057</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>556.443403</td>\n",
       "      <td>0.190769</td>\n",
       "      <td>450.291123</td>\n",
       "      <td>1.797128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sales  Discount  Net Revenue  Return Rate\n",
       "0  1221.539974  0.200000   977.231979     0.439866\n",
       "1  1051.410484  0.190769   850.833715     0.511041\n",
       "2   965.305515  0.100000   868.774964     0.000000\n",
       "3   909.668891  0.190769   736.132057     0.000000\n",
       "4   556.443403  0.190769   450.291123     1.797128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üì¶ Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# üéØ Synthetic messy dataset\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], 100),\n",
    "    'Sales': np.random.normal(1000, 300, 100),\n",
    "    'Discount': np.random.choice([0.1, 0.2, 0.3, np.nan], 100),\n",
    "    'Returns': np.random.choice([0, 1, np.nan], 100)\n",
    "})\n",
    "df.iloc[5] = df.iloc[0]  # duplicate\n",
    "df.loc[10, 'Sales'] = 10000  # outlier\n",
    "\n",
    "# üîß Cleaning Function\n",
    "def clean_data(missing_strategy, outlier_strategy, drop_duplicates):\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Handle missing values\n",
    "    if missing_strategy == 'Fill Mean':\n",
    "        df_clean['Discount'] = df_clean['Discount'].fillna(df_clean['Discount'].mean())\n",
    "        df_clean['Returns'] = df_clean['Returns'].fillna(df_clean['Returns'].mean())\n",
    "    elif missing_strategy == 'Fill Median':\n",
    "        df_clean['Discount'] = df_clean['Discount'].fillna(df_clean['Discount'].median())\n",
    "        df_clean['Returns'] = df_clean['Returns'].fillna(df_clean['Returns'].median())\n",
    "    elif missing_strategy == 'Fill Mode':\n",
    "        df_clean['Discount'] = df_clean['Discount'].fillna(df_clean['Discount'].mode()[0])\n",
    "        df_clean['Returns'] = df_clean['Returns'].fillna(df_clean['Returns'].mode()[0])\n",
    "    elif missing_strategy == 'Fill Constant':\n",
    "        df_clean['Discount'] = df_clean['Discount'].fillna(0.0)\n",
    "        df_clean['Returns'] = df_clean['Returns'].fillna(0)\n",
    "    elif missing_strategy == 'Drop Rows':\n",
    "        df_clean.dropna(inplace=True)\n",
    "\n",
    "    # Handle outliers\n",
    "    if outlier_strategy == 'IQR':\n",
    "        Q1 = df_clean['Sales'].quantile(0.25)\n",
    "        Q3 = df_clean['Sales'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        df_clean = df_clean[(df_clean['Sales'] >= Q1 - 1.5 * IQR) & (df_clean['Sales'] <= Q3 + 1.5 * IQR)]\n",
    "    elif outlier_strategy == 'Z-Score':\n",
    "        z_scores = np.abs(stats.zscore(df_clean['Sales']))\n",
    "        df_clean = df_clean[z_scores < 3]\n",
    "\n",
    "    # Drop duplicates\n",
    "    if drop_duplicates:\n",
    "        df_clean.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# üìä Aggregation Function\n",
    "def aggregate_data(df_clean):\n",
    "    return df_clean.groupby('Region').agg({\n",
    "        'Sales': ['sum', 'mean'],\n",
    "        'Discount': 'mean',\n",
    "        'Returns': 'sum'\n",
    "    }).round(2)\n",
    "\n",
    "# üßÆ Derivation Function\n",
    "def derive_features(df_clean):\n",
    "    df_derived = df_clean.copy()\n",
    "    df_derived['Net Revenue'] = df_derived['Sales'] * (1 - df_derived['Discount'])\n",
    "    df_derived['Return Rate'] = df_derived['Returns'] / (df_derived['Sales'] / 1000)\n",
    "    return df_derived\n",
    "\n",
    "# üéõÔ∏è Widgets\n",
    "missing_dropdown = widgets.Dropdown(\n",
    "    options=['Fill Mean', 'Fill Median', 'Fill Mode', 'Fill Constant', 'Drop Rows'],\n",
    "    value='Fill Mean',\n",
    "    description='Missing Values'\n",
    ")\n",
    "\n",
    "outlier_dropdown = widgets.Dropdown(\n",
    "    options=['None', 'IQR', 'Z-Score'],\n",
    "    value='IQR',\n",
    "    description='Outliers'\n",
    ")\n",
    "\n",
    "duplicate_toggle = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Drop Duplicates'\n",
    ")\n",
    "\n",
    "show_raw_toggle = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show Raw Data'\n",
    ")\n",
    "\n",
    "refresh_button = widgets.Button(description=\"üîÅ Run ETL Simulation\")\n",
    "\n",
    "# üîÑ Callback\n",
    "def on_refresh_clicked(b):\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(\"## üß™ ETL Simulation: Cleaning ‚Üí Aggregation ‚Üí Derivation\"))\n",
    "    display(show_raw_toggle, missing_dropdown, outlier_dropdown, duplicate_toggle, refresh_button)\n",
    "\n",
    "    if show_raw_toggle.value:\n",
    "        display(Markdown(\"### üßæ Raw Unclean Data Sample\"))\n",
    "        display(df.head())\n",
    "\n",
    "    df_clean = clean_data(missing_dropdown.value, outlier_dropdown.value, duplicate_toggle.value)\n",
    "    df_agg = aggregate_data(df_clean)\n",
    "    df_derived = derive_features(df_clean)\n",
    "\n",
    "    display(Markdown(\"### ‚úÖ Cleaned Data Sample\"))\n",
    "    display(df_clean.head())\n",
    "\n",
    "    display(Markdown(\"### üìä Aggregated Summary by Region\"))\n",
    "    display(df_agg)\n",
    "\n",
    "    display(Markdown(\"### üßÆ Derived Features\"))\n",
    "    display(df_derived[['Sales', 'Discount', 'Net Revenue', 'Return Rate']].head())\n",
    "\n",
    "refresh_button.on_click(on_refresh_clicked)\n",
    "\n",
    "# ‚ñ∂Ô∏è Display\n",
    "display(Markdown(\"## üß™ ETL Simulation: Cleaning ‚Üí Aggregation ‚Üí Derivation\"))\n",
    "display(show_raw_toggle, missing_dropdown, outlier_dropdown, duplicate_toggle, refresh_button)\n",
    "on_refresh_clicked(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc912492-5286-43ca-b0de-c5a1a018cd50",
   "metadata": {},
   "source": [
    "### üß† ETL for Business Intelligence ‚Äî Quiz\n",
    "\n",
    "Test your understanding of ETL processes and their role in data-driven decision-making.\n",
    "\n",
    "### üì• Extraction\n",
    "1. **What is the purpose of the 'Extraction' step in ETL?**\n",
    "   - a) To clean the data\n",
    "   - b) To derive new features\n",
    "   - c) To retrieve raw data from source systems\n",
    "   - d) To visualize aggregated metrics\n",
    "\n",
    "2. **In the synthetic dataset, which features were extracted?**\n",
    "   - a) Region, Sales, Discount, Returns\n",
    "   - b) Net Revenue, Return Rate\n",
    "   - c) Aggregated Sales\n",
    "   - d) Cleaned Sales only\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Transformation\n",
    "3. **Which of the following is NOT a transformation applied in the notebook?**\n",
    "   - a) Filling missing values\n",
    "   - b) Removing outliers\n",
    "   - c) Creating visual dashboards\n",
    "   - d) Dropping duplicates\n",
    "\n",
    "4. **What does the 'Net Revenue' feature represent?**\n",
    "   - a) Sales after returns\n",
    "   - b) Sales multiplied by discount\n",
    "   - c) Sales adjusted for discount\n",
    "   - d) Total returns per region\n",
    "\n",
    "5. **Which outlier detection methods are used?**\n",
    "   - a) Box plot and histogram\n",
    "   - b) IQR and Z-score\n",
    "   - c) Mean and median\n",
    "   - d) Min-max scaling\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Load\n",
    "6. **What is the final output of the ETL pipeline in this notebook?**\n",
    "   - a) A cleaned CSV file\n",
    "   - b) A machine learning model\n",
    "   - c) Aggregated and derived data displayed via widgets\n",
    "   - d) A database update\n",
    "\n",
    "7. **Why is aggregation by 'Region' useful in business intelligence?**\n",
    "   - a) It reduces data size\n",
    "   - b) It enables regional performance comparison\n",
    "   - c) It anonymizes customer data\n",
    "   - d) It removes outliers\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Reflection\n",
    "8. **How might different missing value strategies affect business decisions?**\n",
    "   - _Open-ended_\n",
    "\n",
    "9. **What are the risks of skipping the transformation step in ETL?**\n",
    "   - _Open-ended_\n",
    "\n",
    "10. **Suggest one additional feature that could be derived to enhance insight.**\n",
    "   - _Open-ended_\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
