{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0231802-cfd7-4d38-86bf-6efe9276fc57",
   "metadata": {},
   "source": [
    "### 📊 Sampling and Descriptive Statistics\n",
    "\n",
    "Understanding how to summarize and interpret data is foundational in statistics. This module introduces key concepts in sampling, population vs. sample statistics, and types of averages.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Population vs. Sample Statistics\n",
    "\n",
    "| Concept            | Population (Parameter)       | Sample (Statistic)             |\n",
    "|--------------------|------------------------------|--------------------------------|\n",
    "| Mean               | $ \\mu = \\frac{1}{N} \\sum_{i=1}^{N} x_i $ | $ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $ |\n",
    "| Variance           | $ \\sigma^2 = \\frac{1}{N} \\sum (x_i - \\mu)^2 $ | $ s^2 = \\frac{1}{n-1} \\sum (x_i - \\bar{x})^2 $ |\n",
    "| Standard Deviation | $ \\sigma $                | $ s $                        |\n",
    "| Proportion         | $ P $                      | $ \\hat{p} $                  |\n",
    "\n",
    "- **Population**: Entire group of interest  \n",
    "- **Sample**: Subset used to estimate population characteristics\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Sampling Methods\n",
    "\n",
    "- **Simple Random Sampling**: Every member has equal chance  \n",
    "- **Stratified Sampling**: Divide into subgroups and sample proportionally  \n",
    "- **Systematic Sampling**: Select every $k^{th}$ item  \n",
    "- **Cluster Sampling**: Randomly select entire groups\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 Descriptive Statistics\n",
    "\n",
    "Descriptive statistics summarize data using:\n",
    "\n",
    "- **Measures of Central Tendency**: Mean, Median, Mode  \n",
    "- **Measures of Dispersion**: Range, Variance, Standard Deviation  \n",
    "- **Shape**: Skewness, Kurtosis  \n",
    "- **Position**: Percentiles, Quartiles\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Comparison of Mean Types\n",
    "\n",
    "| Type of Mean       | Formula                                      | Use Case                               |\n",
    "|--------------------|----------------------------------------------|----------------------------------------|\n",
    "| Arithmetic Mean    | $ \\bar{x} = \\frac{1}{n} \\sum x_i $         | General average                        |\n",
    "| Geometric Mean     | $ \\left( \\prod x_i \\right)^{1/n} $         | Growth rates, ratios                   |\n",
    "| Harmonic Mean      | $ \\frac{n}{\\sum \\frac{1}{x_i}} $           | Rates, speeds                          |\n",
    "| Median             | Middle value (sorted data)                   | Skewed distributions                   |\n",
    "| Mode               | Most frequent value                          | Categorical or discrete data           |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary\n",
    "\n",
    "- Sampling allows inference from limited data  \n",
    "- Descriptive statistics summarize key features  \n",
    "- Choosing the right average depends on context  \n",
    "- Sample statistics use $n-1$ in variance to reduce bias  \n",
    "- Population statistics assume full data and use $n$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20fd7b97-114e-413b-9d38-a2278d3b72a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666ca2cffe034f2d8b7d3387aa499e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=30, description='Sample Size', min=10, step=10), FloatSlider(value=50.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📊 Interactive Statistics Module (Unweighted, Row-wise Display)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider, IntSlider\n",
    "\n",
    "# Synthetic dataset generator\n",
    "def generate_data(n=30, mean=50, std=10):\n",
    "    np.random.seed(42)\n",
    "    data = np.random.normal(loc=mean, scale=std, size=n)\n",
    "    return np.round(data, 4)  # Round to 4 significant digits\n",
    "\n",
    "# Statistics calculator\n",
    "def compute_statistics(n=30, mean=50, std=10):\n",
    "    x = generate_data(n, mean, std)\n",
    "\n",
    "    # Sample statistics (ddof=1)\n",
    "    mean_sample = np.mean(x)\n",
    "    var_sample = np.var(x, ddof=1)\n",
    "    std_sample = np.std(x, ddof=1)\n",
    "\n",
    "    # Population statistics (ddof=0)\n",
    "    var_pop = np.var(x, ddof=0)\n",
    "    std_pop = np.std(x, ddof=0)\n",
    "\n",
    "    # Display statistics\n",
    "    print(\"📘 Sample Statistics:\")\n",
    "    print(f\"Mean: {mean_sample:.4f}\")\n",
    "    print(f\"Variance (Sample): {var_sample:.4f}\")\n",
    "    print(f\"Standard Deviation (Sample): {std_sample:.4f}\\n\")\n",
    "\n",
    "    print(\"📗 Population Statistics:\")\n",
    "    print(f\"Variance (Population): {var_pop:.4f}\")\n",
    "    print(f\"Standard Deviation (Population): {std_pop:.4f}\\n\")\n",
    "\n",
    "    print(\"📋 Sample Data (25 values per row):\")\n",
    "    for i in range(0, len(x), 25):\n",
    "        row = x[i:i+25]\n",
    "        formatted = \"  \".join(f\"{val:.2f}\" for val in row)\n",
    "        print(formatted)\n",
    "\n",
    "\n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(x, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(mean_sample, color='blue', linestyle='--', label='Sample Mean')\n",
    "    plt.title(\"Distribution of Synthetic Sample Data\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "interact(compute_statistics,\n",
    "         n=IntSlider(min=10, max=100, step=10, value=30, description='Sample Size'),\n",
    "         mean=FloatSlider(min=30, max=70, step=1, value=50, description='Mean'),\n",
    "         std=FloatSlider(min=5, max=20, step=1, value=10, description='Std Dev'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4cb902-85d6-4781-9d44-3e4b0af38285",
   "metadata": {},
   "source": [
    "### ⚖️ Types of Weighted Means: Concepts, Applications, and Limitations\n",
    "\n",
    "Weighted means are used when data points contribute unequally to an average. This module explores different types of weighted means, their formulas, use cases, and potential drawbacks.\n",
    "\n",
    "---\n",
    "\n",
    "### 📐 What Is a Weighted Mean?\n",
    "\n",
    "A weighted mean adjusts each value's contribution based on its assigned weight:\n",
    "\n",
    "$$\n",
    "\\bar{x}_w = \\frac{\\sum w_i x_i}{\\sum w_i}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $x_i$ are the data values\n",
    "- $w_i$ are the corresponding weights\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 Types of Weighted Means\n",
    "\n",
    "| Type               | Formula                                           | Application Example                        | Limitations                              |\n",
    "|--------------------|---------------------------------------------------|---------------------------------------------|-------------------------------------------|\n",
    "| **Arithmetic Weighted Mean** | $$ \\bar{x}_w = \\frac{\\sum w_i x_i}{\\sum w_i} $$ | GPA, average cost, survey scores            | Sensitive to outliers and large weights   |\n",
    "| **Geometric Weighted Mean** | $$ \\bar{x}_g = \\prod x_i^{w_i / \\sum w_i} $$ | Growth rates, portfolio returns             | Cannot handle zero or negative values     |\n",
    "| **Harmonic Weighted Mean** | $$ \\bar{x}_h = \\frac{\\sum w_i}{\\sum \\frac{w_i}{x_i}} $$ | Average speed, rates, efficiency            | Undefined for $x_i = 0$; sensitive to small values |\n",
    "| **Quadratic Mean (RMS)** | $$ \\bar{x}_{rms} = \\sqrt{ \\frac{\\sum w_i x_i^2}{\\sum w_i} } $$ | Signal processing, error analysis           | Overemphasizes large values               |\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 Detailed Descriptions\n",
    "\n",
    "#### 1. Arithmetic Weighted Mean\n",
    "- Most common form\n",
    "- Each value contributes proportionally to its weight\n",
    "- Used in education (GPA), economics (weighted price index), and polling\n",
    "\n",
    "#### 2. Geometric Weighted Mean\n",
    "- Multiplies values raised to weight fractions\n",
    "- Ideal for compounding scenarios (e.g., investment returns)\n",
    "- Cannot be used with zero or negative values\n",
    "\n",
    "#### 3. Harmonic Weighted Mean\n",
    "- Inverse of weighted average of reciprocals\n",
    "- Best for averaging rates (e.g., speed over varying distances)\n",
    "- Sensitive to very small values and undefined for zero\n",
    "\n",
    "#### 4. Quadratic Mean (Root Mean Square)\n",
    "- Square values before averaging\n",
    "- Common in physics and engineering (e.g., RMS voltage)\n",
    "- Amplifies large deviations\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ Summary of Limitations\n",
    "\n",
    "- **Arithmetic**: Skewed by extreme weights or outliers  \n",
    "- **Geometric**: Requires all values $> 0$  \n",
    "- **Harmonic**: Undefined for zero, unstable for small values  \n",
    "- **Quadratic**: Not robust to outliers, emphasizes large values\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Choosing the Right Mean\n",
    "\n",
    "| Scenario                        | Recommended Mean         |\n",
    "|---------------------------------|---------------------------|\n",
    "| Weighted average of scores      | Arithmetic Weighted Mean |\n",
    "| Compounded growth               | Geometric Weighted Mean  |\n",
    "| Averaging rates or speeds       | Harmonic Weighted Mean   |\n",
    "| Signal or error magnitude       | Quadratic Mean (RMS)     |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9053c4f6-1f97-4862-ab3c-749cc288b652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee57d122e754c8fa834a321e3f0feb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=30, description='Sample Size', min=10, step=10), IntSlider(value=10, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# Generate synthetic values\n",
    "def generate_values(n=30, val_min=10, val_max=100):\n",
    "    np.random.seed(42)\n",
    "    return np.round(np.random.uniform(val_min, val_max, size=n), 4)\n",
    "\n",
    "# Normalize weights\n",
    "def normalize(weights):\n",
    "    return weights / np.sum(weights)\n",
    "\n",
    "# Weighting schemes\n",
    "def unweighted_weights(n):\n",
    "    return np.ones(n) / n\n",
    "\n",
    "def random_weights(n, weight_min=1, weight_max=5):\n",
    "    raw = np.random.randint(weight_min, weight_max + 1, size=n)\n",
    "    return normalize(raw)\n",
    "\n",
    "def center_weights(values, val_min, val_max):\n",
    "    midpoint = (val_min + val_max) / 2\n",
    "    distances = np.abs(values - midpoint)\n",
    "    raw = 1 / (distances + 1e-3)\n",
    "    return normalize(raw)\n",
    "\n",
    "# Comparison demo\n",
    "def compare_all_weights(n=30, val_min=10, val_max=100):\n",
    "    values = generate_values(n, val_min, val_max)\n",
    "    w_unweighted = unweighted_weights(n)\n",
    "    w_random = random_weights(n)\n",
    "    w_center = center_weights(values, val_min, val_max)\n",
    "\n",
    "    mean_unweighted = np.average(values, weights=w_unweighted)\n",
    "    mean_random = np.average(values, weights=w_random)\n",
    "    mean_center = np.average(values, weights=w_center)\n",
    "\n",
    "    # Display table\n",
    "    df = pd.DataFrame({\n",
    "        'Value': values,\n",
    "        'Unweighted': np.round(w_unweighted, 4),\n",
    "        'Random Weight': np.round(w_random, 4),\n",
    "        'Center Weight': np.round(w_center, 4)\n",
    "    })\n",
    "    print(df)\n",
    "\n",
    "    print(f\"\\n⚖️ Mean Comparisons:\")\n",
    "    print(f\"🔹 Unweighted Mean: {mean_unweighted:.4f}\")\n",
    "    print(f\"🔹 Random Weighted Mean: {mean_random:.4f}\")\n",
    "    print(f\"🔹 Center-Weighted Mean: {mean_center:.4f}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(values, np.zeros_like(values), s=w_unweighted * 1000, c='gray', alpha=0.4, label='Unweighted')\n",
    "    plt.scatter(values, np.ones_like(values), s=w_random * 1000, c='blue', alpha=0.5, label='Random Weights')\n",
    "    plt.scatter(values, np.ones_like(values) * 2, s=w_center * 1000, c='orange', alpha=0.5, label='Center Weights')\n",
    "    plt.axvline(mean_unweighted, color='gray', linestyle='--', label='Unweighted Mean')\n",
    "    plt.axvline(mean_random, color='blue', linestyle='--', label='Random Mean')\n",
    "    plt.axvline(mean_center, color='orange', linestyle='--', label='Center Mean')\n",
    "    plt.yticks([0, 1, 2], ['Unweighted', 'Random', 'Center'])\n",
    "    plt.title(\"Comparison of Weighting Schemes (Normalized)\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "interact(compare_all_weights,\n",
    "         n=IntSlider(min=10, max=100, step=10, value=30, description='Sample Size'),\n",
    "         val_min=IntSlider(min=0, max=50, step=5, value=10, description='Min Value'),\n",
    "         val_max=IntSlider(min=50, max=150, step=10, value=100, description='Max Value'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0684b4-752e-4a42-a94c-b9e33040f4ee",
   "metadata": {},
   "source": [
    "### 📏 Goodness-of-Fit Measures: Overview and Interpretation\n",
    "\n",
    "Goodness-of-fit metrics quantify how well a model or simulation replicates observed data. These measures help evaluate prediction accuracy, error magnitude, and overall model reliability.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔢 Common Goodness-of-Fit Metrics\n",
    "\n",
    "| Measure                     | Formula                                                                 | Interpretation                                                             |\n",
    "|----------------------------|-------------------------------------------------------------------------|----------------------------------------------------------------------------|\n",
    "| **RMSE (Root Mean Square Error)** | $$ \\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (O_i - P_i)^2 } $$         | Penalizes large errors; lower is better                                   |\n",
    "| **MAE (Mean Absolute Error)**     | $$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |O_i - P_i| $$                        | Average magnitude of error; less sensitive to outliers                    |\n",
    "| **NSE (Nash–Sutcliffe Efficiency)** | $$ \\text{NSE} = 1 - \\frac{ \\sum (O_i - P_i)^2 }{ \\sum (O_i - \\bar{O})^2 } $$ | Compares model to mean of observed; 1 is perfect, 0 is mean model         |\n",
    "| **R² (Coefficient of Determination)** | $$ R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}} $$                     | Proportion of variance explained; closer to 1 is better                   |\n",
    "| **Log-Normalized RMSE**           | $$ \\text{Log-RMSE} = \\sqrt{ \\frac{1}{n} \\sum (\\log O_i - \\log P_i)^2 } $$   | Useful when data spans orders of magnitude; reduces skew from large values |\n",
    "| **Bias (Mean Error)**             | $$ \\text{Bias} = \\frac{1}{n} \\sum (P_i - O_i) $$                            | Indicates systematic over- or under-prediction                            |\n",
    "| **Percent Bias (PBIAS)**         | $$ \\text{PBIAS} = 100 \\times \\frac{ \\sum (O_i - P_i) }{ \\sum O_i } $$       | Expresses bias as percentage; ideal value is 0                            |\n",
    "\n",
    "---\n",
    "\n",
    "### 📘 Interpretation Guidelines\n",
    "\n",
    "| Metric        | Ideal Value | Notes                                                                 |\n",
    "|---------------|-------------|-----------------------------------------------------------------------|\n",
    "| RMSE, MAE     | → 0         | Lower values indicate better fit                                     |\n",
    "| NSE, R²       | → 1         | Higher values indicate better predictive power                       |\n",
    "| Bias, PBIAS   | → 0         | Positive = overprediction; Negative = underprediction                |\n",
    "| Log-RMSE      | Contextual  | Useful for log-transformed or multiplicative error models            |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Use Cases\n",
    "\n",
    "| Scenario                          | Recommended Metric(s)                     |\n",
    "|----------------------------------|-------------------------------------------|\n",
    "| General error magnitude          | RMSE, MAE                                  |\n",
    "| Hydrology / environmental models | NSE, PBIAS                                 |\n",
    "| Log-transformed or skewed data   | Log-RMSE                                   |\n",
    "| Model bias detection             | Bias, Percent Bias                         |\n",
    "| Regression performance           | R², RMSE                                   |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ Limitations\n",
    "\n",
    "- RMSE is sensitive to large errors (outliers).\n",
    "- NSE can be misleading if observed variance is low.\n",
    "- Log-RMSE requires strictly positive values.\n",
    "- R² does not indicate bias or error magnitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfd6aed-d5a7-41da-9fe7-1f81652d902b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ec4f93c42641679d5d26b0837e1da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=30, description='Time Steps', min=10, step=5), FloatSlider(value=0.25, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ca7b1eb06949aa995f38a7d38f8f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, Output\n",
    "\n",
    "# Output widget\n",
    "out = Output()\n",
    "\n",
    "# Standard growth model (e.g., logistic-like)\n",
    "def generate_observed_growth(n, r=0.2, K=100, P0=10):\n",
    "    t = np.arange(n)\n",
    "    observed = K / (1 + ((K - P0) / P0) * np.exp(-r * t))\n",
    "    return t, observed\n",
    "\n",
    "# Simulated growth model (user-controlled)\n",
    "def generate_simulated_growth(n, r_sim=0.25, K_sim=95, P0_sim=12):\n",
    "    t = np.arange(n)\n",
    "    simulated = K_sim / (1 + ((K_sim - P0_sim) / P0_sim) * np.exp(-r_sim * t))\n",
    "    return simulated\n",
    "\n",
    "# Goodness-of-fit metrics\n",
    "def compute_metrics(observed, predicted):\n",
    "    eps = 1e-6\n",
    "    mean_obs = np.mean(observed)\n",
    "    residuals = observed - predicted\n",
    "\n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    mae = np.mean(np.abs(residuals))\n",
    "    bias = np.mean(predicted - observed)\n",
    "    pbias = 100 * np.sum(observed - predicted) / np.sum(observed)\n",
    "    nse = 1 - np.sum(residuals**2) / np.sum((observed - mean_obs)**2)\n",
    "    r2 = 1 - np.sum(residuals**2) / np.sum((observed - mean_obs)**2)\n",
    "    log_rmse = np.sqrt(np.mean((np.log(observed + eps) - np.log(predicted + eps))**2))\n",
    "\n",
    "    return {\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Bias\": bias,\n",
    "        \"PBIAS (%)\": pbias,\n",
    "        \"NSE\": nse,\n",
    "        \"R²\": r2,\n",
    "        \"Log-RMSE\": log_rmse\n",
    "    }\n",
    "\n",
    "# Interactive comparison\n",
    "def compare_growth_models(n=30, r_sim=0.25, K_sim=95, P0_sim=12):\n",
    "    t, observed = generate_observed_growth(n)\n",
    "    simulated = generate_simulated_growth(n, r_sim, K_sim, P0_sim)\n",
    "    metrics = compute_metrics(observed, simulated)\n",
    "\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        print(\"📘 Goodness-of-Fit Metrics:\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "        print(\"\\n📗 Interpretation:\")\n",
    "        print(\"✅ Lower RMSE/MAE → better fit\")\n",
    "        print(\"✅ NSE and R² close to 1 → strong predictive power\")\n",
    "        print(\"✅ Bias and PBIAS near 0 → minimal systematic error\")\n",
    "        print(\"✅ Log-RMSE useful for skewed or multiplicative data\")\n",
    "\n",
    "        # Plot comparison\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(t, observed, label=\"Observed Growth\", marker='o')\n",
    "        plt.plot(t, simulated, label=\"Simulated Growth\", marker='x')\n",
    "        plt.title(\"Observed vs. Simulated Growth Model\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Population\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Interactive controls\n",
    "interact(\n",
    "    compare_growth_models,\n",
    "    n=IntSlider(min=10, max=100, step=5, value=30, description=\"Time Steps\"),\n",
    "    r_sim=FloatSlider(min=0.1, max=0.5, step=0.01, value=0.25, description=\"Growth Rate\"),\n",
    "    K_sim=FloatSlider(min=50, max=150, step=5, value=95, description=\"Carrying Capacity\"),\n",
    "    P0_sim=FloatSlider(min=5, max=30, step=1, value=12, description=\"Initial Population\")\n",
    ")\n",
    "\n",
    "out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27950e7e-40c7-4a50-884b-ae444cc98d7e",
   "metadata": {},
   "source": [
    "### 🎲 Understanding Probability and Its Role in Risk Assessment\n",
    "\n",
    "### 📘 What Is Probability?\n",
    "\n",
    "- **1** means the event is **certain**.\n",
    "- Values between **0 and 1** reflect varying degrees of **uncertainty**.\n",
    "- Probability is foundational to:\n",
    "  - **Statistics**\n",
    "  - **Decision-making**\n",
    "  - **Machine learning**\n",
    "  - **Engineering risk analysis**\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 Why Is Probability Important?\n",
    "\n",
    "| **Domain**              | **Role of Probability**                                                             |\n",
    "|-------------------------|--------------------------------------------------------------------------------------|\n",
    "| **Statistics**          | Models randomness in sampling, inference, and prediction.                          |\n",
    "| **Engineering**         | Assesses reliability, failure rates, and safety margins.                           |\n",
    "| **Computer Science**    | Powers algorithms in AI, cryptography, and simulations.                            |\n",
    "| **Finance**             | Quantifies market risk, portfolio volatility, and insurance models.                |\n",
    "| **Environmental Science** | Forecasts extreme events like floods, droughts, and pollutant dispersion.       |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚖️ Probability in Risk Assessment\n",
    "\n",
    "Risk assessment involves estimating the **likelihood** and **impact** of adverse outcomes. Probability helps:\n",
    "\n",
    "- Model **uncertainty** in system behavior (e.g., soil failure, structural collapse).\n",
    "- Quantify **exposure** to hazards (e.g., earthquakes, contamination).\n",
    "- Support **decision-making** under uncertainty (e.g., cost-benefit analysis, safety thresholds).\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Example: Geotechnical Risk\n",
    "\n",
    "In slope stability analysis:\n",
    "\n",
    "- Probability of failure is estimated using **soil strength variability**.\n",
    "- **Monte Carlo simulations** or **probabilistic limit equilibrium methods** are used.\n",
    "- **Risk = Probability × Consequence**\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Key Probability Concepts\n",
    "\n",
    "| **Concept**         | **Description**                                                                 |\n",
    "|---------------------|----------------------------------------------------------------------------------|\n",
    "| **Experiment**       | A repeatable process with uncertain outcome (e.g., rolling a die).             |\n",
    "| **Sample Space**     | The set of all possible outcomes.                                               |\n",
    "| **Event**            | A subset of outcomes (e.g., rolling an even number).                           |\n",
    "| **Probability Rule** | $P(A) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total outcomes}}$     |\n",
    "| **Complement Rule**  | $P(\\text{not } A) = 1 - P(A)$                                                   |\n",
    "| **Addition Rule**    | $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$                                       |\n",
    "| **Multiplication Rule** | $P(A \\cap B) = P(A) \\cdot P(B|A)$ (if dependent)                            |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a8aa9-605d-4956-b806-b8667382ae3b",
   "metadata": {},
   "source": [
    "### 🎯 Interactive Simulation: Empirical Probability and Return Period\n",
    "\n",
    "This simulation demonstrates how to estimate the **empirical probability** of an event exceeding a threshold and compute its **return period** using synthetic data.\n",
    "\n",
    "### 🔍 What the Code Does\n",
    "\n",
    "- **Generates synthetic event magnitudes** using a uniform distribution between `val_min` and `val_max`.\n",
    "- Allows the user to select a **threshold** value.\n",
    "- Calculates:\n",
    "  - The number of events that **exceed the threshold**.\n",
    "  - The **empirical probability** of exceedance:  \n",
    "    $P(\\text{event}) = \\frac{\\text{Number of exceedances}}{\\text{Total events}}$\n",
    "  - The **return period** (or recurrence interval):  \n",
    "    $\\text{Return Period} = \\frac{1}{P(\\text{event})}$\n",
    "\n",
    "### 📈 Visualization\n",
    "\n",
    "- A histogram shows the distribution of event magnitudes.\n",
    "- A red dashed line marks the selected threshold.\n",
    "- Summary statistics are printed to reinforce interpretation.\n",
    "\n",
    "### 🧪 Applications\n",
    "\n",
    "This simulation is useful for exploring:\n",
    "- Flood frequency analysis\n",
    "- Earthquake magnitude exceedance\n",
    "- Slope failure probability\n",
    "- Any domain where **event magnitude vs. threshold** matters\n",
    "\n",
    "### ⚙️ Interactive Controls\n",
    "\n",
    "- `Sample Size`: Number of synthetic events generated.\n",
    "- `Min Value` and `Max Value`: Range of event magnitudes.\n",
    "- `Threshold`: Value used to define a \"critical\" or \"extreme\" event.\n",
    "\n",
    "### 📊 Example Use Case\n",
    "\n",
    "If you set:\n",
    "- `val_min = 0`, `val_max = 100`\n",
    "- `threshold = 80`\n",
    "- `n = 100`\n",
    "\n",
    "The simulation will estimate how often events exceed 80 and how frequently such events are expected to recur.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to extend this with time-series simulation or allow multiple thresholds for comparative risk analysis?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dcdc4c4-df9f-4c6a-8e55-f9c26f64295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294cbc3f5a074f26a7561cd0779705a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='Sample Size', max=500, min=50, step=50), IntSlider(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "# Generate synthetic time-series event magnitudes\n",
    "def generate_time_series(n=100, val_min=0, val_max=100):\n",
    "    np.random.seed(42)\n",
    "    magnitudes = np.round(np.random.uniform(val_min, val_max, size=n), 2)\n",
    "    time = np.arange(1, n + 1)\n",
    "    return pd.DataFrame({'Time': time, 'Magnitude': magnitudes})\n",
    "\n",
    "# Simulation with multiple thresholds\n",
    "def multi_threshold_demo(n=100, val_min=0, val_max=100, t1=60, t2=80, t3=100):\n",
    "    df = generate_time_series(n, val_min, val_max)\n",
    "    thresholds = [t1, t2, t3]\n",
    "    results = []\n",
    "\n",
    "    for t in thresholds:\n",
    "        exceed = df['Magnitude'] > t\n",
    "        prob = exceed.sum() / n\n",
    "        rp = 1 / prob if prob > 0 else np.inf\n",
    "        results.append((t, prob, rp))\n",
    "        df[f'> {t}'] = exceed\n",
    "\n",
    "    # Display results\n",
    "    print(\"📊 Empirical Probability and Return Periods:\")\n",
    "    for t, p, r in results:\n",
    "        print(f\"Threshold {t:>3}:  Probability = {p:.4f},  Return Period = {r:.2f} events\")\n",
    "\n",
    "    # Plot time series\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df['Time'], df['Magnitude'], marker='o', linestyle='-', color='gray', label='Event Magnitude')\n",
    "    for t in thresholds:\n",
    "        plt.axhline(t, linestyle='--', label=f'Threshold {t}')\n",
    "    plt.title(\"Synthetic Time-Series of Event Magnitudes\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "interact(multi_threshold_demo,\n",
    "         n=IntSlider(min=50, max=500, step=50, value=100, description='Sample Size'),\n",
    "         val_min=IntSlider(min=0, max=50, step=5, value=0, description='Min Value'),\n",
    "         val_max=IntSlider(min=50, max=150, step=10, value=100, description='Max Value'),\n",
    "         t1=FloatSlider(min=0, max=150, step=1, value=60, description='Threshold 1'),\n",
    "         t2=FloatSlider(min=0, max=150, step=1, value=80, description='Threshold 2'),\n",
    "         t3=FloatSlider(min=0, max=150, step=1, value=100, description='Threshold 3'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6105bc0-65d3-49bb-9de6-dead3081d466",
   "metadata": {},
   "source": [
    "### 📊 Using Theoretical Distributions in Risk and Probability Analysis\n",
    "\n",
    "When empirical data is scarce, unreliable, or incomplete, we turn to **theoretical probability distributions** to model uncertainty and estimate risk. These distributions are based on mathematical assumptions and are widely used in engineering, environmental science, and decision analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### 📘 Why Use Theoretical Distributions?\n",
    "\n",
    "- **Empirical distributions** rely on observed data, which may be:\n",
    "  - Too sparse (e.g., rare events like major earthquakes)\n",
    "  - Incomplete (e.g., short monitoring periods)\n",
    "  - Biased or noisy\n",
    "\n",
    "- **Theoretical distributions** provide:\n",
    "  - A structured way to model uncertainty\n",
    "  - Flexibility to simulate rare or extreme events\n",
    "  - A foundation for probabilistic design and risk assessment\n",
    "\n",
    "---\n",
    "\n",
    "### 📐 Common Theoretical Distributions\n",
    "\n",
    "| Distribution        | Typical Use Case                                 | Shape Characteristics                    |\n",
    "|---------------------|--------------------------------------------------|-------------------------------------------|\n",
    "| **Normal**          | Measurement errors, material properties         | Symmetric, bell-shaped                    |\n",
    "| **Lognormal**       | Soil permeability, rainfall intensity            | Skewed right, non-negative                |\n",
    "| **Exponential**     | Time between failures, hazard occurrence         | Memoryless, decreasing tail               |\n",
    "| **Weibull**         | Reliability, fatigue life                        | Flexible shape for increasing/decreasing hazard |\n",
    "| **Gumbel**          | Extreme value modeling (e.g., floods, wind)      | Models maxima/minima of distributions     |\n",
    "| **Binomial**        | Discrete event counts (e.g., success/failure)    | Finite trials, fixed probability          |\n",
    "| **Poisson**         | Rare event frequency (e.g., landslides/year)     | Count-based, low probability              |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚖️ Application in Risk Assessment\n",
    "\n",
    "Theoretical distributions help estimate:\n",
    "\n",
    "- **Probability of exceedance**:  \n",
    "  $P(X > x)$ for a critical threshold $x$\n",
    "- **Return period**:  \n",
    "  $\\text{Return Period} = \\frac{1}{P(\\text{event})}$\n",
    "- **Confidence intervals** for uncertain parameters\n",
    "- **Failure probabilities** in reliability models\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Example: Flood Risk Using Gumbel Distribution\n",
    "\n",
    "If historical flood data is limited, we can fit a **Gumbel distribution** to estimate:\n",
    "\n",
    "- Probability of a flood exceeding 500 m³/s\n",
    "- Expected return period of such an event\n",
    "- Design thresholds for levees or drainage systems\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Key Takeaways\n",
    "\n",
    "- Theoretical distributions are essential when empirical data is insufficient.\n",
    "- Choice of distribution depends on the nature of the variable (continuous vs. discrete, symmetric vs. skewed).\n",
    "- They enable simulation, forecasting, and probabilistic design under uncertainty.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f747446-80c8-4e8a-88bd-49ebecb2d505",
   "metadata": {},
   "source": [
    "## Distribution fitting and goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "333d39c5-c23c-48f4-9338-cb54394b34b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41632da26c644b989f81095301e1afd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Simulate', style=ButtonStyle()), But…"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from ipywidgets import interact, SelectMultiple, FloatSlider, IntSlider, Button, VBox, HBox, Output\n",
    "\n",
    "# Output widget for dynamic display\n",
    "out = Output()\n",
    "\n",
    "# Available distributions\n",
    "available_distributions = {\n",
    "    \"Normal\": stats.norm,\n",
    "    \"Lognormal\": stats.lognorm,\n",
    "    \"Exponential\": stats.expon,\n",
    "    \"Weibull\": stats.weibull_min\n",
    "}\n",
    "\n",
    "# Global data container\n",
    "data = None\n",
    "\n",
    "# Simulation function\n",
    "def simulate_data(n=500, shape=2.0, scale=10.0):\n",
    "    global data\n",
    "    np.random.seed(42)\n",
    "    data = np.random.gamma(shape=shape, scale=scale, size=n)\n",
    "\n",
    "# Fit and analyze selected distributions\n",
    "def analyze(selected, threshold):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        if data is None:\n",
    "            print(\"⚠️ Please click 'Simulate' first.\")\n",
    "            return\n",
    "\n",
    "        x = np.linspace(min(data), max(data), 100)\n",
    "        fit_results = []\n",
    "\n",
    "        # Empirical exceedance\n",
    "        exceed_emp = data > threshold\n",
    "        prob_emp = exceed_emp.sum() / len(data)\n",
    "        rp_emp = 1 / prob_emp if prob_emp > 0 else np.inf\n",
    "\n",
    "        print(f\"📊 Empirical Probability of Exceeding {threshold:.2f}: {prob_emp:.4f}\")\n",
    "        print(f\"🔁 Empirical Return Period: {rp_emp:.2f} events\\n\")\n",
    "\n",
    "        for name in selected:\n",
    "            dist = available_distributions[name]\n",
    "            params = dist.fit(data)\n",
    "            pdf_fitted = dist.pdf(x, *params)\n",
    "            ks_stat, ks_p = stats.kstest(data, dist.name, args=params)\n",
    "            log_likelihood = np.sum(dist.logpdf(data, *params))\n",
    "            k = len(params)\n",
    "            aic = 2 * k - 2 * log_likelihood\n",
    "\n",
    "            # Confidence intervals (approximate using bootstrap)\n",
    "            ci_lower = np.percentile(data, 2.5)\n",
    "            ci_upper = np.percentile(data, 97.5)\n",
    "\n",
    "            # Theoretical exceedance\n",
    "            prob_theo = dist.sf(threshold, *params)\n",
    "            rp_theo = 1 / prob_theo if prob_theo > 0 else np.inf\n",
    "\n",
    "            fit_results.append({\n",
    "                \"Distribution\": name,\n",
    "                \"KS Statistic\": round(ks_stat, 4),\n",
    "                \"KS p-value\": round(ks_p, 4),\n",
    "                \"AIC\": round(aic, 2),\n",
    "                \"95% CI\": f\"[{ci_lower:.2f}, {ci_upper:.2f}]\",\n",
    "                \"P(X > threshold)\": round(prob_theo, 4),\n",
    "                \"Return Period\": round(rp_theo, 2)\n",
    "            })\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.hist(data, bins=30, density=True, alpha=0.5, label=\"Empirical\")\n",
    "            plt.plot(x, pdf_fitted, label=f\"{name} Fit\", linewidth=2)\n",
    "            plt.axvline(threshold, color='red', linestyle='--', label=f\"Threshold = {threshold}\")\n",
    "            plt.title(f\"{name} Distribution Fit\")\n",
    "            plt.xlabel(\"Value\")\n",
    "            plt.ylabel(\"Density\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        # Summary table\n",
    "        df_results = pd.DataFrame(fit_results)\n",
    "        print(\"📊 Goodness-of-Fit and Risk Summary:\")\n",
    "        display(df_results.sort_values(\"AIC\"))\n",
    "\n",
    "# Widgets\n",
    "simulate_btn = Button(description=\"Simulate\", button_style='success')\n",
    "simulate_btn.on_click(lambda b: simulate_data())\n",
    "\n",
    "distribution_selector = SelectMultiple(\n",
    "    options=list(available_distributions.keys()),\n",
    "    value=[\"Normal\", \"Lognormal\"],\n",
    "    description=\"Distributions\"\n",
    ")\n",
    "\n",
    "threshold_slider = FloatSlider(\n",
    "    value=80,\n",
    "    min=0,\n",
    "    max=200,\n",
    "    step=1,\n",
    "    description=\"Threshold\"\n",
    ")\n",
    "\n",
    "analyze_btn = Button(description=\"Analyze\", button_style='info')\n",
    "analyze_btn.on_click(lambda b: analyze(distribution_selector.value, threshold_slider.value))\n",
    "\n",
    "# Layout\n",
    "VBox([\n",
    "    HBox([simulate_btn, analyze_btn]),\n",
    "    distribution_selector,\n",
    "    threshold_slider,\n",
    "    out\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f4bf3-cf2b-4b58-98fd-8103200cd85e",
   "metadata": {},
   "source": [
    "### 🧪 Hypothesis Testing: Concepts, Types, and Applications\n",
    "\n",
    "Hypothesis testing is a statistical method used to make decisions or inferences about population parameters based on sample data.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Core Concepts\n",
    "\n",
    "- **Null Hypothesis ($H_0$)**: Assumes no effect or no difference.\n",
    "- **Alternative Hypothesis ($H_1$ or $H_a$)**: Assumes a real effect or difference exists.\n",
    "- **Test Statistic**: A value computed from sample data used to decide whether to reject $H_0$.\n",
    "- **p-value**: Probability of observing the test statistic under $H_0$.\n",
    "- **Significance Level ($\\alpha$)**: Threshold for rejecting $H_0$, commonly 0.05.\n",
    "- **Confidence Interval**: Range of values likely to contain the true parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 Types of Hypothesis Tests\n",
    "\n",
    "| Test Type              | Use Case                                      | Assumptions                            | Example Scenario                        |\n",
    "|------------------------|-----------------------------------------------|----------------------------------------|-----------------------------------------|\n",
    "| **Z-test**             | Compare means (large $n$, known $\\sigma$)     | Normal distribution, known variance    | Mean weight of manufactured parts       |\n",
    "| **t-test**             | Compare means (small $n$, unknown $\\sigma$)   | Normality, equal variance (for 2-sample) | Drug effectiveness between two groups   |\n",
    "| **Chi-square test**    | Test for independence or goodness-of-fit      | Categorical data, expected counts ≥ 5  | Survey response vs. age group           |\n",
    "| **ANOVA**              | Compare means across ≥3 groups                | Normality, equal variance              | Crop yield across different fertilizers |\n",
    "| **Mann–Whitney U**     | Non-parametric test for two independent groups| No assumption of normality             | Median income between regions           |\n",
    "| **Wilcoxon Signed-Rank** | Non-parametric test for paired samples     | Symmetric distribution of differences  | Before/after treatment scores           |\n",
    "| **Kolmogorov–Smirnov** | Compare distributions or test normality       | Continuous data                        | Fit of theoretical distribution          |\n",
    "| **Log-rank test**      | Compare survival curves                       | Censored data, proportional hazards    | Time-to-failure in reliability studies  |\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Decision Process\n",
    "\n",
    "1. **Formulate hypotheses**: $H_0$ and $H_1$\n",
    "2. **Choose significance level**: $\\alpha = 0.05$\n",
    "3. **Select appropriate test** based on data type and assumptions\n",
    "4. **Compute test statistic and p-value**\n",
    "5. **Compare p-value to $\\alpha$**:\n",
    "   - If $p < \\alpha$: Reject $H_0$\n",
    "   - If $p \\geq \\alpha$: Fail to reject $H_0$\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Applications in Engineering and Science\n",
    "\n",
    "- **Quality control**: Z-test, t-test for process monitoring\n",
    "- **Environmental analysis**: ANOVA for comparing pollutant levels\n",
    "- **Reliability**: Log-rank test for component lifetimes\n",
    "- **Geotechnical studies**: Non-parametric tests for soil properties\n",
    "- **Remote sensing**: Chi-square for classification accuracy\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to extend this with interactive examples or code snippets for each test?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47370cdd-e83e-4d10-9db6-884d3fc74a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4335211e0acc4e46be132025f74f5dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Simulate', style=ButtonStyle()), But…"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from ipywidgets import interact, IntSlider, FloatSlider, Button, Output, VBox, HBox\n",
    "\n",
    "# Output widget\n",
    "out = Output()\n",
    "\n",
    "# Global data\n",
    "group1 = None\n",
    "group2 = None\n",
    "\n",
    "# Simulate data\n",
    "def simulate_ttest(n=30, mu1=50, mu2=55, sigma=10):\n",
    "    global group1, group2\n",
    "    np.random.seed(42)\n",
    "    group1 = np.random.normal(loc=mu1, scale=sigma, size=n)\n",
    "    group2 = np.random.normal(loc=mu2, scale=sigma, size=n)\n",
    "\n",
    "# Run t-test and plot\n",
    "def run_ttest():\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        if group1 is None or group2 is None:\n",
    "            print(\"⚠️ Please simulate data first.\")\n",
    "            return\n",
    "\n",
    "        # Perform t-test\n",
    "        stat, p = ttest_ind(group1, group2)\n",
    "        mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.hist(group1, bins=20, alpha=0.6, label=\"Group 1\", color='blue')\n",
    "        plt.hist(group2, bins=20, alpha=0.6, label=\"Group 2\", color='orange')\n",
    "        plt.axvline(mean1, color='blue', linestyle='--', label=f\"Mean 1 = {mean1:.2f}\")\n",
    "        plt.axvline(mean2, color='orange', linestyle='--', label=f\"Mean 2 = {mean2:.2f}\")\n",
    "        plt.title(\"Distribution of Two Groups\")\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Summary\n",
    "        print(\"📊 Two-Sample t-Test Results:\")\n",
    "        print(f\"t-statistic: {stat:.4f}\")\n",
    "        print(f\"p-value: {p:.4f}\")\n",
    "        if p < 0.05:\n",
    "            print(\"✅ Significant difference (reject H₀)\")\n",
    "        else:\n",
    "            print(\"❌ No significant difference (fail to reject H₀)\")\n",
    "\n",
    "# Widgets\n",
    "simulate_btn = Button(description=\"Simulate\", button_style='success')\n",
    "simulate_btn.on_click(lambda b: simulate_ttest(n_slider.value, mu1_slider.value, mu2_slider.value))\n",
    "\n",
    "run_btn = Button(description=\"Run t-Test\", button_style='info')\n",
    "run_btn.on_click(lambda b: run_ttest())\n",
    "\n",
    "n_slider = IntSlider(value=30, min=10, max=100, step=5, description=\"Sample Size\")\n",
    "mu1_slider = FloatSlider(value=50, min=30, max=70, step=1, description=\"Mean Group 1\")\n",
    "mu2_slider = FloatSlider(value=55, min=30, max=70, step=1, description=\"Mean Group 2\")\n",
    "\n",
    "# Layout\n",
    "VBox([\n",
    "    HBox([simulate_btn, run_btn]),\n",
    "    n_slider,\n",
    "    mu1_slider,\n",
    "    mu2_slider,\n",
    "    out\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a60e6e-9c74-42fa-b67f-9c47a0cd581a",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9025969-0d8c-4b74-b8c7-56094cd08a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b14a2f8d6742c381bf60ed65498e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Test Type', index=1, options=('Z-test', 't-test', 'Chi-square test…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bf9852f7df49e19f70e71ac5d0aaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from ipywidgets import Dropdown, IntSlider, FloatSlider, Button, Output, VBox, HBox\n",
    "\n",
    "# Output widget\n",
    "out = Output()\n",
    "\n",
    "# Global data containers\n",
    "data_store = {}\n",
    "\n",
    "# Test options\n",
    "test_options = [\n",
    "    \"Z-test\",\n",
    "    \"t-test\",\n",
    "    \"Chi-square test\",\n",
    "    \"ANOVA\",\n",
    "    \"Mann–Whitney U\",\n",
    "    \"Wilcoxon Signed-Rank\",\n",
    "    \"Kolmogorov–Smirnov\",\n",
    "    \"Log-rank test (simulated)\"\n",
    "]\n",
    "\n",
    "# Simulate data\n",
    "def simulate_data(n, mu1, mu2):\n",
    "    np.random.seed(42)\n",
    "    data_store.clear()\n",
    "    data_store[\"x1\"] = np.random.normal(mu1, 10, n)\n",
    "    data_store[\"x2\"] = np.random.normal(mu2, 10, n)\n",
    "    data_store[\"before\"] = np.random.normal(mu1, 10, n)\n",
    "    data_store[\"after\"] = data_store[\"before\"] + np.random.normal(mu2 - mu1, 5, n)\n",
    "    data_store[\"anova\"] = [\n",
    "        np.random.normal(50, 10, n),\n",
    "        np.random.normal(55, 10, n),\n",
    "        np.random.normal(60, 10, n)\n",
    "    ]\n",
    "    data_store[\"survival1\"] = np.random.exponential(scale=10, size=n)\n",
    "    data_store[\"survival2\"] = np.random.exponential(scale=15, size=n)\n",
    "\n",
    "# Analyze selected test\n",
    "def analyze_test(test_type):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        if not data_store:\n",
    "            print(\"⚠️ Please click 'Simulate' first.\")\n",
    "            return\n",
    "\n",
    "        def interpret(p, alpha=0.05):\n",
    "            if p < alpha:\n",
    "                return f\"✅ Result is statistically significant (p < {alpha}). Reject the null hypothesis.\"\n",
    "            else:\n",
    "                return f\"❌ Result is not statistically significant (p ≥ {alpha}). Fail to reject the null hypothesis.\"\n",
    "\n",
    "        if test_type == \"Z-test\":\n",
    "            mu = 10\n",
    "            x1, x2 = data_store[\"x1\"], data_store[\"x2\"]\n",
    "            z = (np.mean(x1) - np.mean(x2)) / np.sqrt(mu**2/len(x1) + mu**2/len(x2))\n",
    "            p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "            print(f\"Z-test: z = {z:.4f}, p = {p:.4f}\")\n",
    "            print(interpret(p))\n",
    "\n",
    "        elif test_type == \"t-test\":\n",
    "            stat, p = stats.ttest_ind(data_store[\"x1\"], data_store[\"x2\"])\n",
    "            print(f\"t-test: t = {stat:.4f}, p = {p:.4f}\")\n",
    "            print(interpret(p))\n",
    "\n",
    "        elif test_type == \"Chi-square test\":\n",
    "            observed = np.array([[20, 30], [25, 25]])\n",
    "            stat, p, _, _ = stats.chi2_contingency(observed)\n",
    "            print(f\"Chi-square test: χ² = {stat:.4f}, p = {p:.4f}\")\n",
    "            print(interpret(p))\n",
    "\n",
    "        elif test_type == \"ANOVA\":\n",
    "            stat, p = stats.f_oneway(*data_store[\"anova\"])\n",
    "            print(f\"ANOVA: F = {stat:.4f}, p = {p:.4f}\")\n",
    "            print(interpret(p))\n",
    "\n",
    "        elif test_type == \"Mann–Whitney U\":\n",
    "            stat, p = stats.mannwhitneyu(data_store[\"x1\"], data_store[\"x2\"])\n",
    "            print(f\"Mann–Whitney U: U = {stat:.4f}, p = {p:.4f}\")\n",
    "            print(interpret(p))\n",
    "\n",
    "        elif test_type == \"Wilcoxon Signed-Rank\":\n",
    "            stat, p = stats.wilcoxon(data_store[\"before\"], data_store[\"after\"])\n",
    "            print(f\"Wilcoxon Signed-Rank: W = {stat:.4f}, p = {p:.4f}\")\n",
    "            print(interpret(p))\n",
    "\n",
    "        elif test_type == \"Kolmogorov–Smirnov\":\n",
    "            x = data_store[\"x1\"]\n",
    "            stat, p = stats.kstest(x, 'norm', args=(np.mean(x), np.std(x)))\n",
    "            print(f\"Kolmogorov–Smirnov: D = {stat:.4f}, p = {p:.4f}\")\n",
    "            print(interpret(p))\n",
    "\n",
    "        elif test_type == \"Log-rank test (simulated)\":\n",
    "            stat, p = stats.ttest_ind(data_store[\"survival1\"], data_store[\"survival2\"])\n",
    "            print(f\"Log-rank (simulated): t = {stat:.4f}, p = {p:.4f}\")\n",
    "            print(interpret(p))\n",
    "\n",
    "        # Optional plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        if test_type in [\"Z-test\", \"t-test\", \"Mann–Whitney U\"]:\n",
    "            plt.hist(data_store[\"x1\"], bins=20, alpha=0.6, label=\"Group 1\")\n",
    "            plt.hist(data_store[\"x2\"], bins=20, alpha=0.6, label=\"Group 2\")\n",
    "        elif test_type == \"Wilcoxon Signed-Rank\":\n",
    "            plt.plot(data_store[\"before\"], label=\"Before\", marker='o')\n",
    "            plt.plot(data_store[\"after\"], label=\"After\", marker='x')\n",
    "        elif test_type == \"ANOVA\":\n",
    "            plt.boxplot(data_store[\"anova\"], labels=[\"Group 1\", \"Group 2\", \"Group 3\"])\n",
    "        elif test_type == \"Kolmogorov–Smirnov\":\n",
    "            x = data_store[\"x1\"]\n",
    "            plt.hist(x, bins=20, alpha=0.7, label=\"Sample\")\n",
    "            plt.plot(np.sort(x), stats.norm.pdf(np.sort(x), np.mean(x), np.std(x)), label=\"Normal PDF\")\n",
    "        elif test_type == \"Log-rank test (simulated)\":\n",
    "            plt.hist(data_store[\"survival1\"], bins=20, alpha=0.6, label=\"Group 1\")\n",
    "            plt.hist(data_store[\"survival2\"], bins=20, alpha=0.6, label=\"Group 2\")\n",
    "        plt.title(f\"{test_type} Visualization\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Widgets\n",
    "test_selector = Dropdown(options=test_options, value=\"t-test\", description=\"Test Type\")\n",
    "n_slider = IntSlider(value=30, min=10, max=100, step=5, description=\"Sample Size\")\n",
    "mu1_slider = FloatSlider(value=50, min=30, max=70, step=1, description=\"Mean Group 1\")\n",
    "mu2_slider = FloatSlider(value=55, min=30, max=70, step=1, description=\"Mean Group 2\")\n",
    "\n",
    "simulate_btn = Button(description=\"Simulate\", button_style='success')\n",
    "simulate_btn.on_click(lambda b: simulate_data(n_slider.value, mu1_slider.value, mu2_slider.value))\n",
    "\n",
    "analyze_btn = Button(description=\"Analyze\", button_style='info')\n",
    "analyze_btn.on_click(lambda b: analyze_test(test_selector.value))\n",
    "\n",
    "# Layout\n",
    "VBox([\n",
    "    HBox([simulate_btn, analyze_btn]),\n",
    "    test_selector,\n",
    "    n_slider,\n",
    "    mu1_slider,\n",
    "    mu2_slider,\n",
    "    out\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a27ff2-4c7a-4684-889a-c0a428c22a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
